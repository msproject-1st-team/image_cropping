import numpy as np
import cv2
import os

import torch
import torchvision.transforms as T
from PIL import Image
 
def adjust_brightness(image, value):
    """ì´ë¯¸ì§€ ë°ê¸° ì¡°ì •"""
    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)
    h, s, v = cv2.split(hsv)
    v = np.clip(v + value, 0, 255).astype(np.uint8)
    adjusted_hsv = cv2.merge([h, s, v])
    return cv2.cvtColor(adjusted_hsv, cv2.COLOR_HSV2BGR)
 
def adjust_gamma(image, gamma=1.0):
    """ê°ë§ˆ ì¡°ì •"""
    inv_gamma = 1.0 / gamma
    table = np.array([(i / 255.0) ** inv_gamma * 255 for i in range(256)]).astype(np.uint8)
    return cv2.LUT(image, table)
 
def add_padding(image, padding, color=(0, 0, 0)):
    """ì´ë¯¸ì§€ íŒ¨ë”© ì¶”ê°€"""
    return cv2.copyMakeBorder(image, padding, padding, padding, padding, cv2.BORDER_CONSTANT, value=color)
 
def rotate_image(image, angle):
    """ì´ë¯¸ì§€ íšŒì „"""
    (h, w) = image.shape[:2]
    center = (w // 2, h // 2)
    matrix = cv2.getRotationMatrix2D(center, -angle, 1.0)
    return cv2.warpAffine(image, matrix, (w, h))
 
def translate_image(image, x, y):
    """ì´ë¯¸ì§€ ìˆ˜ì§, ìˆ˜í‰ ì´ë™"""
    matrix = np.float32([[1, 0, x], [0, 1, y]])
    return cv2.warpAffine(image, matrix, (image.shape[1], image.shape[0]))
 
def crop_image(image, x, y, width, height):
    """ì´ë¯¸ì§€ í¬ë¡­ (ë¶€ë¶„ ì˜ë¼ë‚´ê¸°)"""
    return image[y:y+height, x:x+width]
 
def flip_image(image, mode):
    """ì´ë¯¸ì§€ ì¢Œìš°/ìƒí•˜ ë°˜ì „ (mode: 1=ì¢Œìš°, 0=ìƒí•˜, -1=ìƒí•˜ì¢Œìš°)"""
    return cv2.flip(image, mode)

def remove_background(image):
    """DeepLabV3ë¥¼ ì´ìš©í•´ ì‹ ì²´ ë¶€ìœ„ ë¶„í•  í›„ ë°°ê²½ ì œê±° ë° í¬ë¡­ (íˆ¬ëª… ë°°ê²½ ì ìš©)"""
    model = torch.hub.load('pytorch/vision:v0.10.0', 'deeplabv3_resnet101', pretrained=True)
    model.eval()

    image_pil = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # BGR -> RGB ë³€í™˜
    image_pil = Image.fromarray(image_pil)

    preprocess = T.Compose([
        T.Resize((520, 520)),
        T.ToTensor(),
        T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
    ])
    input_tensor = preprocess(image_pil).unsqueeze(0)

    with torch.no_grad():
        output = model(input_tensor)["out"][0]

    output_predictions = output.argmax(0).byte().cpu().numpy()
    mask = (output_predictions == 15).astype(np.uint8) * 255  # ì‹ ì²´ ë¶€ë¶„ì„ 255ë¡œ ì„¤ì •

    # **ë§ˆìŠ¤í¬ í¬ê¸° ì¡°ì • (ì›ë³¸ ì´ë¯¸ì§€ í¬ê¸°ì— ë§ì¶¤)**
    mask = cv2.resize(mask, (image.shape[1], image.shape[0]), interpolation=cv2.INTER_NEAREST)

    # **ë°”ìš´ë”© ë°•ìŠ¤ë¡œ ì‹ ì²´ ì˜ì—­ ì°¾ê¸°**
    coords = cv2.findNonZero(mask)
    if coords is None:
        return None  # ì‹ ì²´ ê°ì§€ ì•ˆë˜ë©´ None ë°˜í™˜

    x, y, w, h = cv2.boundingRect(coords)  # ë°”ìš´ë”© ë°•ìŠ¤

    # ğŸŸ¢ **RGBA ë³€í™˜**
    b, g, r = cv2.split(image)
    alpha = mask  # alpha ì±„ë„ë¡œ ì‚¬ìš©í•  ë§ˆìŠ¤í¬

    # **ì—¬ê¸°ì„œ í¬ê¸° ì˜¤ë¥˜ ë°©ì§€**
    if alpha.shape != b.shape:
        alpha = cv2.resize(alpha, (b.shape[1], b.shape[0]))

    rgba = cv2.merge([b, g, r, alpha])  # í¬ê¸° ë§ì¶˜ í›„ merge

    # **ì‹ ì²´ ë¶€ë¶„ë§Œ í¬ë¡­**
    cropped = rgba[y:y+h, x:x+w]

    return cropped


# ì‚¬ìš© ì˜ˆì‹œ
# image = cv2.imread("example.jpg")
# bright_image = adjust_brightness(image, 50)
# gamma_image = adjust_gamma(image, 1.5)
# padded_image = add_padding(image, 20, (255, 255, 255))
# rotated_image = rotate_image(image, 45)
# translated_image = translate_image(image, 30, -20)
# cropped_image = crop_image(image, 50, 50, 100, 100)
# flipped_image = flip_image(image, 1)
 
# ì‹¤ì œ ì‚¬ìš©
if __name__ == "__main__":
    input_dir = "C:/Users/EL0018/Downloads/test" # ì‚¬ì§„ ì›ë³¸ í´ë”
    output_dir = "C:/Users/EL0018/Downloads/output" # ì¦ê°•í•œ ì‚¬ì§„(ë³€í™˜í•œ ì‚¬ì§„) ì €ì¥í•  í´ë”
    images = os.listdir(input_dir)
    print(f"ì›ë³¸ ì‚¬ì§„ ê°œìˆ˜ : {len(images)}")
    i = 0
    for image_name in images:
        img = cv2.imread(os.path.join(input_dir, image_name))
        ###################### ì‚¬ìš©í•  í•¨ìˆ˜ ì…ë ¥ ##############################
        # img = rotate_image(img, 90)
        res_img = remove_background(img)
        #####################################################################
        output_file_name = os.path.join(output_dir, f'{image_name}_{str(i)}.png')
        if res_img is not None:
            cv2.imwrite(output_file_name, res_img)
        else:
            cv2.imwrite(output_file_name, img)
        i = i + 1
        # if i > 10000:
        #     break